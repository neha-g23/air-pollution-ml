{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b13f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Residual] CO(GT): threshold ≈ 2.076\n",
      "[Residual] C6H6(GT): threshold ≈ 9.050\n",
      "[Residual] NOx(GT): threshold ≈ 207.564\n",
      "[Residual] NO2(GT): threshold ≈ 70.053\n",
      "[Summary] IsolationForest anomalies: 131\n",
      "[Summary] Residual anomalies (sum over pollutants): 594\n",
      "Saved anomalies_summary.csv and figures under /Users/aayushveturi/Desktop/COMP9417/COMP9417_GroupProject/src/reports\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# config: pollutants + mapping to sensors\n",
    "POLLUTANTS = [\"CO(GT)\", \"C6H6(GT)\", \"NOx(GT)\", \"NO2(GT)\"]\n",
    "GT_TO_SENSOR = {\n",
    "    \"CO(GT)\": \"PT08.S1(CO)\",\n",
    "    \"C6H6(GT)\": \"PT08.S2(NMHC)\",\n",
    "    \"NOx(GT)\": \"PT08.S3(NOx)\",\n",
    "    \"NO2(GT)\": \"PT08.S4(NO2)\",\n",
    "}\n",
    "\n",
    "\n",
    "# ---------- 0) I/O utils ----------\n",
    "def get_reports_dir():\n",
    "    \"\"\"Return reports directory under src/ or working directory.\"\"\"\n",
    "    # In Jupyter, __file__ does NOT exist → fallback to cwd\n",
    "    try:\n",
    "        base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        base_dir = os.getcwd()\n",
    "\n",
    "    reports = os.path.join(base_dir, \"reports\")\n",
    "    os.makedirs(reports, exist_ok=True)\n",
    "    return reports\n",
    "\n",
    "#  1) Load + minimal clean\n",
    "def load_and_clean_data(path=\"air+quality/AirQualityUCI.xlsx\"):\n",
    "    df = pd.read_excel(path)\n",
    "    \n",
    "    # remove trailing spaces in column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Merge Date + Time\n",
    "    df[\"DateTime\"] = pd.to_datetime(\n",
    "        df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str),\n",
    "        errors=\"coerce\",\n",
    "        dayfirst=True,\n",
    "    )\n",
    "    df.drop([\"Date\", \"Time\"], axis=1, inplace=True)\n",
    "    \n",
    "    # replace invalid sensor/sentinals with NaN\n",
    "    df.replace(-200, np.nan, inplace=True)\n",
    "    \n",
    "    # drop rows if DateTime could not be read\n",
    "    df = df.dropna(subset=[\"DateTime\"]).sort_values(\"DateTime\").reset_index(drop=True)\n",
    "    \n",
    "    # add temporal features to use for anomaly context\n",
    "    df[\"hour\"] = df[\"DateTime\"].dt.hour\n",
    "    df[\"weekday\"] = df[\"DateTime\"].dt.day_name()\n",
    "    df[\"month\"] = df[\"DateTime\"].dt.month\n",
    "    return df\n",
    "\n",
    "\n",
    "# 2) Residual-based anomalies (generic) \n",
    "def detect_residual_anomalies(df, col, win=12, k_sigma=3.5):\n",
    "    \"\"\"\n",
    "    Detect anomalies based on rolling median and Median Absolute Deviation (MAD).\n",
    "    Any point deviating more than k_sigma * sigma_robust from rolling baseline\n",
    "    is flagged as anomalous.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    short = col.split(\"(\")[0]  # e.g. CO(GT) -> \"CO\"\n",
    "    \n",
    "    # names for new columns\n",
    "    med_col = f\"{col}_median\"\n",
    "    resid_col = f\"{col}_resid\"\n",
    "    flag_col = f\"is_anom_resid_{short}\"\n",
    "\n",
    "    # rolling median baseline\n",
    "    df[med_col] = df[col].rolling(win, center=True,\n",
    "                                  min_periods=max(3, win // 2)).median()\n",
    "    \n",
    "    # compute residual from rolling baseline\n",
    "    df[resid_col] = df[col] - df[med_col]\n",
    "\n",
    "    # compte MAD-based robust sigma\n",
    "    mad = np.nanmedian(np.abs(df[resid_col] - np.nanmedian(df[resid_col])))\n",
    "    sigma = 1.4826 * mad\n",
    "    \n",
    "    # threshold to detect anomalies\n",
    "    thr = k_sigma * sigma if np.isfinite(sigma) and sigma > 0 else np.nan\n",
    "    \n",
    "    # flag anomalies if threshold exists\n",
    "    df[flag_col] = np.abs(df[resid_col]) > thr if np.isfinite(thr) else False\n",
    "    \n",
    "    return df, flag_col, thr\n",
    "\n",
    "\n",
    "# 3) Multivariate Isolation Forest \n",
    "def detect_isolation_forest(df, features=None, contamination=0.05, random_state=42):\n",
    "    if features is None:\n",
    "        # by default use pollutants + meteorological variables\n",
    "        features = POLLUTANTS + [\"T\", \"RH\", \"AH\"]\n",
    "\n",
    "    # drop rows missing predictors\n",
    "    X = df[features].dropna()\n",
    "    \n",
    "    # scale features \n",
    "    scaler = StandardScaler()\n",
    "    X_sc = scaler.fit_transform(X.values)\n",
    "\n",
    "    # fit isolation forest\n",
    "    iso = IsolationForest(contamination=contamination, random_state=random_state)\n",
    "    y_pred = iso.fit_predict(X_sc)  # -1 = anomaly\n",
    "\n",
    "    df_iso = df.copy()\n",
    "    df_iso[\"is_anom_iso\"] = False\n",
    "    df_iso.loc[X.index, \"is_anom_iso\"] = y_pred == -1\n",
    "    return df_iso, features\n",
    "\n",
    "\n",
    "# 4) Sensor–truth consistency (generic)\n",
    "def sensor_truth_mismatch(df, truth_col, sensor_col, z_thr=3.0):\n",
    "    \"\"\"\n",
    "    For a given GT pollutant and its sensor column, flag rows where\n",
    "    their standardized values differ strongly.\n",
    "    Writes is_mismatch_<short> column.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    short = truth_col.split(\"(\")[0]\n",
    "    flag_col = f\"is_mismatch_{short}\"\n",
    "\n",
    "    # if sensor column missing, create \"all False\" flag\n",
    "    if sensor_col not in df.columns:\n",
    "        df[flag_col] = False\n",
    "        return df, flag_col\n",
    "\n",
    "    # extract valid rows\n",
    "    sub = df[[truth_col, sensor_col]].dropna()\n",
    "    if sub.empty:\n",
    "        df[flag_col] = False\n",
    "        return df, flag_col\n",
    "\n",
    "    # z-standardise each series manually\n",
    "    ztruth = (sub[truth_col] - sub[truth_col].mean()) / sub[truth_col].std(ddof=0)\n",
    "    zsens = (sub[sensor_col] - sub[sensor_col].mean()) / sub[sensor_col].std(ddof=0)\n",
    "    \n",
    "    # absolute standard deviation difference between truth and sensor\n",
    "    delta = (ztruth - zsens).abs()\n",
    "    \n",
    "    # points where difference > threshold\n",
    "    mismatch_idx = sub.index[delta > z_thr]\n",
    "\n",
    "    df[flag_col] = False\n",
    "    df.loc[mismatch_idx, flag_col] = True\n",
    "    return df, flag_col\n",
    "\n",
    "\n",
    "# 5) Plotting helpers (scatter-only versions)\n",
    "def plot_ts_with_anomalies(df, col, resid_flag_col, reports_dir):\n",
    "    \"\"\"\n",
    "    Scatter plot for pollutant time-series with anomaly markers.\n",
    "    \"\"\"\n",
    "    short = col.split(\"(\")[0]\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Base scatter (all points)\n",
    "    plt.scatter(df[\"DateTime\"], df[col], s=6, alpha=0.5, label=col, color=\"steelblue\")\n",
    "\n",
    "    # Residual anomalies\n",
    "    if resid_flag_col in df.columns and df[resid_flag_col].any():\n",
    "        mask = df[resid_flag_col]\n",
    "        plt.scatter(df.loc[mask, \"DateTime\"], df.loc[mask, col],\n",
    "                    s=20, color=\"red\", label=\"Residual anomaly\")\n",
    "\n",
    "    # Isolation Forest anomalies\n",
    "    if \"is_anom_iso\" in df.columns and df[\"is_anom_iso\"].any():\n",
    "        mask = df[\"is_anom_iso\"]\n",
    "        plt.scatter(df.loc[mask, \"DateTime\"], df.loc[mask, col],\n",
    "                    s=20, color=\"orange\", alpha=0.8, label=\"IsolationForest anomaly\")\n",
    "\n",
    "    plt.title(f\"{col} with Anomalies (Scatter Plot)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(col)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    fname = f\"fig_{short.lower()}_anomalies.png\"\n",
    "    plt.savefig(os.path.join(reports_dir, fname), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_sensor_truth(df, truth_col, sensor_col, mismatch_flag_col, reports_dir):\n",
    "    \"\"\"\n",
    "    Scatter plot version of sensor vs truth overlay.\n",
    "    \"\"\"\n",
    "    if sensor_col not in df.columns:\n",
    "        return\n",
    "\n",
    "    short = truth_col.split(\"(\")[0]\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "    # Scatter truth and sensor\n",
    "    plt.scatter(df[\"DateTime\"], df[truth_col],\n",
    "                s=8, alpha=0.6, label=truth_col, color=\"dodgerblue\")\n",
    "\n",
    "    plt.scatter(df[\"DateTime\"], df[sensor_col],\n",
    "                s=8, alpha=0.4, label=sensor_col, color=\"orange\")\n",
    "\n",
    "    # Mismatch flags\n",
    "    if mismatch_flag_col in df.columns and df[mismatch_flag_col].any():\n",
    "        m = df[mismatch_flag_col]\n",
    "        plt.scatter(df.loc[m, \"DateTime\"], df.loc[m, truth_col],\n",
    "                    s=20, color=\"purple\", label=\"Sensor–truth mismatch\")\n",
    "\n",
    "    plt.title(f\"{short}: Truth vs Sensor (Scatter Plot)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    fname = f\"fig_{short.lower()}_truth_vs_sensor.png\"\n",
    "    plt.savefig(os.path.join(reports_dir, fname), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_anomaly_context(df, reports_dir):\n",
    "    # Union over all residual flags + iso\n",
    "    resid_flags = [c for c in df.columns if c.startswith(\"is_anom_resid_\")]\n",
    "    union = df.get(\"is_anom_iso\", False)\n",
    "    for c in resid_flags:\n",
    "        union = union | df[c]\n",
    "    anom = df.loc[union].copy()\n",
    "    if anom.empty:\n",
    "        return\n",
    "\n",
    "    # By weekday\n",
    "    ax = anom[\"weekday\"].value_counts().reindex(\n",
    "        [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    ).plot(kind=\"bar\", figsize=(6, 4))\n",
    "    ax.set_title(\"Anomalies by Weekday\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(reports_dir, \"fig_anom_by_weekday.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # By hour\n",
    "    ax = anom[\"hour\"].value_counts().sort_index().plot(kind=\"bar\", figsize=(8, 4))\n",
    "    ax.set_title(\"Anomalies by Hour\")\n",
    "    ax.set_xlabel(\"Hour\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(reports_dir, \"fig_anom_by_hour.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# 6) MAIN \n",
    "if __name__ == \"__main__\":\n",
    "    reports = get_reports_dir()\n",
    "\n",
    "    df = load_and_clean_data(\"air+quality/AirQualityUCI.xlsx\")\n",
    "\n",
    "    # A) residual anomalies per pollutant\n",
    "    resid_flag_cols = []\n",
    "    for col in POLLUTANTS:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        df, flag_col, thr_used = detect_residual_anomalies(df, col=col, win=12, k_sigma=3.5)\n",
    "        resid_flag_cols.append(flag_col)\n",
    "        print(f\"[Residual] {col}: threshold ≈ {thr_used:.3f}\" if np.isfinite(thr_used)\n",
    "              else f\"[Residual] {col}: threshold not computed\")\n",
    "    \n",
    "    # multivariate IF\n",
    "    df, used_feats = detect_isolation_forest(df,\n",
    "                                             features=POLLUTANTS + [\"T\", \"RH\", \"AH\"],\n",
    "                                             contamination=0.05)\n",
    "\n",
    "    # sensor–truth mismatch for each pollutant with a sensor\n",
    "    mismatch_flag_cols = []\n",
    "    for gt, sensor in GT_TO_SENSOR.items():\n",
    "        if gt in df.columns and sensor in df.columns:\n",
    "            df, flag_col = sensor_truth_mismatch(df, truth_col=gt, sensor_col=sensor, z_thr=3.0)\n",
    "            mismatch_flag_cols.append(flag_col)\n",
    "        elif gt in df.columns:\n",
    "            \n",
    "            # still create column (all False) for consistency\n",
    "            df[gt] = df[gt]\n",
    "            \n",
    "    # save CSV with flags\n",
    "    out_cols = [\"DateTime\"] + POLLUTANTS + [\"T\", \"RH\", \"AH\", \"hour\", \"weekday\", \"month\"]\n",
    "    out_cols += resid_flag_cols + [\"is_anom_iso\"] + mismatch_flag_cols\n",
    "    out_cols = [c for c in out_cols if c in df.columns]\n",
    "    df[out_cols].to_csv(os.path.join(reports, \"anomalies_summary.csv\"), index=False)\n",
    "\n",
    "    # E) plots per pollutant\n",
    "    for col, resid_flag in zip(POLLUTANTS, resid_flag_cols):\n",
    "        if col in df.columns:\n",
    "            plot_ts_with_anomalies(df, col, resid_flag, reports)\n",
    "            sensor_col = GT_TO_SENSOR.get(col)\n",
    "            if sensor_col:\n",
    "                mismatch_flag_col = f\"is_mismatch_{col.split('(')[0]}\"\n",
    "                plot_sensor_truth(df, col, sensor_col, mismatch_flag_col, reports)\n",
    "\n",
    "    # context plots\n",
    "    plot_anomaly_context(df, reports)\n",
    "\n",
    "    # quick summary block\n",
    "    total_iso = int(df[\"is_anom_iso\"].sum())\n",
    "    total_resid = sum(int(df[c].sum()) for c in resid_flag_cols)\n",
    "    print(f\"[Summary] IsolationForest anomalies: {total_iso}\")\n",
    "    print(f\"[Summary] Residual anomalies (sum over pollutants): {total_resid}\")\n",
    "    print(f\"Saved anomalies_summary.csv and figures under {reports}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
